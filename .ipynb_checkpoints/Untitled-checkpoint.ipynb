{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import time\n",
    "import tqdm\n",
    "import shutil\n",
    "import keras\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from tensorflow.python.keras import regularizers\n",
    "from tensorflow.python.keras.models import Sequential, load_model\n",
    "from tensorflow.python.keras.callbacks import EarlyStopping\n",
    "from keras.utils import to_categorical\n",
    "from sklearn.model_selection import train_test_split\n",
    "from tensorflow.python.keras.layers import Dense, Dropout, Flatten, Conv2D, MaxPooling2D, LSTM, ConvLSTM2D, AveragePooling2D, TimeDistributed\n",
    "from tensorflow.python.keras.utils.data_utils import Sequence\n",
    "\n",
    "\n",
    "def reshape_model(x_train, x_test):\n",
    "#     x_train = np.reshape(x_train, (x_train.shape[0], 1, x_train.shape[1], x_train.shape[2]))\n",
    "#     x_test = np.reshape(x_test, (x_test.shape[0], 1, x_test.shape[1], x_test.shape[2]))\n",
    "\n",
    "    x_train = np.reshape(x_train, (x_train.shape[0], x_train.shape[1], x_train.shape[2], 1))\n",
    "    x_test = np.reshape(x_test, (x_test.shape[0], x_test.shape[1], x_test.shape[2], 1))\n",
    "\n",
    "#     x_train = np.reshape(x_train, (x_train.shape[0], x_train.shape[2], x_train.shape[1], 1, 1))\n",
    "#     x_test = np.reshape(x_test, (x_test.shape[0], x_train.shape[2], x_train.shape[1], 1, 1))\n",
    "\n",
    "    return x_train, x_test\n",
    "\n",
    "# For Sequence trainig example\n",
    "class BatchSequence(Sequence):\n",
    "    def __init__(self, x_set, y_set, batch_size):\n",
    "        self.x, self.y = x_set, y_set\n",
    "        self.batch_size = batch_size\n",
    "\n",
    "    def __len__(self):\n",
    "        return int(np.ceil(len(self.x) / float(self.batch_size)))\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "#         matrixes = []\n",
    "#         for name in self.x.iloc[idx * self.batch_size:(idx + 1) * self.batch_size]['ID']:\n",
    "#             sample = pd.read_csv(name + \".csv\")\n",
    "#             sample.rename(columns={'Unnamed: 0': 'ID'}, inplace=True)\n",
    "#             sample = np.array(sample.drop(['ID'], axis=1))\n",
    "#             matrixes.append(sample)\n",
    "\n",
    "        batch_x = self.x[idx * self.batch_size:(idx + 1) * self.batch_size]\n",
    "        batch_y = self.y[idx * self.batch_size:(idx + 1) * self.batch_size]\n",
    "\n",
    "        return batch_x, batch_y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load csv file\n",
    "# train = pd.read_csv('train_200.csv')\n",
    "train = pd.read_csv('train_clean_200.csv')\n",
    "train.rename(columns={'Unnamed: 0': 'ID'}, inplace=True)\n",
    "\n",
    "# Build train and test dataset\n",
    "y = np.array(train.drop(['ID'], axis=1)).squeeze()\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(train, y, test_size=0.2, random_state=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "matrixes = []\n",
    "for sample in X_test.ID:\n",
    "    ms = pd.read_csv(sample + \".csv\")\n",
    "    ms.rename(columns={'Unnamed: 0': 'ID'}, inplace=True)\n",
    "    ms = np.array(ms.drop(['ID'], axis=1))\n",
    "    matrixes.append(ms)\n",
    "\n",
    "X_test = np.array(matrixes)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "matrixes = []\n",
    "for sample in X_train.ID:\n",
    "    ms = pd.read_csv(sample + \".csv\")\n",
    "    ms.rename(columns={'Unnamed: 0': 'ID'}, inplace=True)\n",
    "    ms = np.array(ms.drop(['ID'], axis=1))\n",
    "    matrixes.append(ms)\n",
    "\n",
    "x_train = np.array(matrixes)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_train = to_categorical(y_train, 2)\n",
    "y_test = to_categorical(y_test, 2)\n",
    "\n",
    "x_train, x_test = reshape_model(x_train, X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((7193, 60, 200, 1), (1799, 60, 200, 1))"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x_train.shape, x_test.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# from EEGModels import EEGNet, ShallowConvNet, DeepConvNet\n",
    "\n",
    "# model = EEGNet(nb_classes=2, Chans=60, Samples=200)\n",
    "\n",
    "# # compile the model and set the optimizers\n",
    "# model.compile(loss='categorical_crossentropy', optimizer='adam', \n",
    "#               metrics = ['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'EarlyStopping' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-7-7db993ec2dc8>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[1;32m----> 1\u001b[1;33m earlystop_callback = EarlyStopping(\n\u001b[0m\u001b[0;32m      2\u001b[0m   \u001b[0mmonitor\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;34m'val_accuracy'\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mmin_delta\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m0.0001\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      3\u001b[0m   patience=1, verbose=1, mode='auto')\n\u001b[0;32m      4\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      5\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mNameError\u001b[0m: name 'EarlyStopping' is not defined"
     ]
    }
   ],
   "source": [
    "earlystop_callback = EarlyStopping(\n",
    "  monitor='val_accuracy', min_delta=0.0001,\n",
    "  patience=1, verbose=1, mode='auto')\n",
    "\n",
    "\n",
    "model = Sequential()\n",
    "model.add(Conv2D(60, (30, 1), activation=\"relu\", padding=\"same\", data_format=\"channels_last\"))\n",
    "model.add(Conv2D(60, (1, 60), activation=\"relu\", padding=\"same\", data_format=\"channels_last\"))\n",
    "# model.add(AveragePooling2D((30, 1), strides=(15, 1)))\n",
    "model.add(Dropout(0.5))\n",
    "model.add(Flatten())\n",
    "model.add(Dense(80, activation=\"relu\"))\n",
    "model.add(Dense(2, activation=\"softmax\"))\n",
    "model.compile(loss=\"categorical_crossentropy\", optimizer=\"adam\", metrics=[\"acc\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "collapsed": true
   },
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "Shape must be at least rank 3 but is rank 2 for '{{node lstm_2/lstm_cell_2/BiasAdd}} = BiasAdd[T=DT_FLOAT, data_format=\"NCHW\"](lstm_2/lstm_cell_2/add, lstm_2/lstm_cell_2/BiasAdd/ReadVariableOp)' with input shapes: [?,160], [160].",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mInvalidArgumentError\u001b[0m                      Traceback (most recent call last)",
      "\u001b[1;32m~\\AppData\\Local\\Programs\\Python\\Python37\\lib\\site-packages\\tensorflow\\python\\framework\\ops.py\u001b[0m in \u001b[0;36m_create_c_op\u001b[1;34m(graph, node_def, inputs, control_inputs, op_def)\u001b[0m\n\u001b[0;32m   1653\u001b[0m   \u001b[1;32mtry\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1654\u001b[1;33m     \u001b[0mc_op\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mpywrap_tf_session\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mTF_FinishOperation\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mop_desc\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   1655\u001b[0m   \u001b[1;32mexcept\u001b[0m \u001b[0merrors\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mInvalidArgumentError\u001b[0m \u001b[1;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mInvalidArgumentError\u001b[0m: Shape must be at least rank 3 but is rank 2 for '{{node lstm_2/lstm_cell_2/BiasAdd}} = BiasAdd[T=DT_FLOAT, data_format=\"NCHW\"](lstm_2/lstm_cell_2/add, lstm_2/lstm_cell_2/BiasAdd/ReadVariableOp)' with input shapes: [?,160], [160].",
      "\nDuring handling of the above exception, another exception occurred:\n",
      "\u001b[1;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-19-e3e3fad44534>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      4\u001b[0m \u001b[0mmodel\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0madd\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mAveragePooling2D\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;36m5\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;36m1\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mstrides\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;36m5\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;36m1\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      5\u001b[0m \u001b[0mmodel\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0madd\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mTimeDistributed\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mFlatten\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 6\u001b[1;33m \u001b[0mmodel\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0madd\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mLSTM\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;36m40\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mactivation\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;34m\"sigmoid\"\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mdropout\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m0.25\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mreturn_sequences\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;32mTrue\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      7\u001b[0m \u001b[0mmodel\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0madd\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mDense\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mnclasses\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mactivation\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;34m\"softmax\"\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      8\u001b[0m \u001b[0mmodel\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mcompile\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mloss\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;34m\"categorical_crossentropy\"\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0moptimizer\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;34m\"rmsprop\"\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mmetrics\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m\"acc\"\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\AppData\\Local\\Programs\\Python\\Python37\\lib\\site-packages\\tensorflow\\python\\training\\tracking\\base.py\u001b[0m in \u001b[0;36m_method_wrapper\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m    454\u001b[0m     \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_self_setattr_tracking\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;32mFalse\u001b[0m  \u001b[1;31m# pylint: disable=protected-access\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    455\u001b[0m     \u001b[1;32mtry\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 456\u001b[1;33m       \u001b[0mresult\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mmethod\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m*\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    457\u001b[0m     \u001b[1;32mfinally\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    458\u001b[0m       \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_self_setattr_tracking\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mprevious_value\u001b[0m  \u001b[1;31m# pylint: disable=protected-access\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\AppData\\Local\\Programs\\Python\\Python37\\lib\\site-packages\\tensorflow\\python\\keras\\engine\\sequential.py\u001b[0m in \u001b[0;36madd\u001b[1;34m(self, layer)\u001b[0m\n\u001b[0;32m    211\u001b[0m       \u001b[1;31m# If the model is being built continuously on top of an input layer:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    212\u001b[0m       \u001b[1;31m# refresh its output.\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 213\u001b[1;33m       \u001b[0moutput_tensor\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mlayer\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0moutputs\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    214\u001b[0m       \u001b[1;32mif\u001b[0m \u001b[0mlen\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mnest\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mflatten\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0moutput_tensor\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;33m!=\u001b[0m \u001b[1;36m1\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    215\u001b[0m         \u001b[1;32mraise\u001b[0m \u001b[0mValueError\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mSINGLE_LAYER_OUTPUT_ERROR_MSG\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\AppData\\Local\\Programs\\Python\\Python37\\lib\\site-packages\\tensorflow\\python\\keras\\layers\\recurrent.py\u001b[0m in \u001b[0;36m__call__\u001b[1;34m(self, inputs, initial_state, constants, **kwargs)\u001b[0m\n\u001b[0;32m    652\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    653\u001b[0m     \u001b[1;32mif\u001b[0m \u001b[0minitial_state\u001b[0m \u001b[1;32mis\u001b[0m \u001b[1;32mNone\u001b[0m \u001b[1;32mand\u001b[0m \u001b[0mconstants\u001b[0m \u001b[1;32mis\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 654\u001b[1;33m       \u001b[1;32mreturn\u001b[0m \u001b[0msuper\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mRNN\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m__call__\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0minputs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    655\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    656\u001b[0m     \u001b[1;31m# If any of `initial_state` or `constants` are specified and are Keras\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\AppData\\Local\\Programs\\Python\\Python37\\lib\\site-packages\\tensorflow\\python\\keras\\engine\\base_layer.py\u001b[0m in \u001b[0;36m__call__\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m    920\u001b[0m                     not base_layer_utils.is_in_eager_or_tf_function()):\n\u001b[0;32m    921\u001b[0m                   \u001b[1;32mwith\u001b[0m \u001b[0mauto_control_deps\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mAutomaticControlDependencies\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;32mas\u001b[0m \u001b[0macd\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 922\u001b[1;33m                     \u001b[0moutputs\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mcall_fn\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mcast_inputs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m*\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    923\u001b[0m                     \u001b[1;31m# Wrap Tensors in `outputs` in `tf.identity` to avoid\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    924\u001b[0m                     \u001b[1;31m# circular dependencies.\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\AppData\\Local\\Programs\\Python\\Python37\\lib\\site-packages\\tensorflow\\python\\keras\\layers\\recurrent_v2.py\u001b[0m in \u001b[0;36mcall\u001b[1;34m(self, inputs, mask, training, initial_state)\u001b[0m\n\u001b[0;32m   1136\u001b[0m           \u001b[0minput_length\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mrow_lengths\u001b[0m \u001b[1;32mif\u001b[0m \u001b[0mrow_lengths\u001b[0m \u001b[1;32mis\u001b[0m \u001b[1;32mnot\u001b[0m \u001b[1;32mNone\u001b[0m \u001b[1;32melse\u001b[0m \u001b[0mtimesteps\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1137\u001b[0m           \u001b[0mtime_major\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mtime_major\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1138\u001b[1;33m           zero_output_for_mask=self.zero_output_for_mask)\n\u001b[0m\u001b[0;32m   1139\u001b[0m       \u001b[0mruntime\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0m_runtime\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0m_RUNTIME_UNKNOWN\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1140\u001b[0m     \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\AppData\\Local\\Programs\\Python\\Python37\\lib\\site-packages\\tensorflow\\python\\keras\\backend.py\u001b[0m in \u001b[0;36mrnn\u001b[1;34m(step_function, inputs, initial_states, go_backwards, mask, constants, unroll, input_length, time_major, zero_output_for_mask)\u001b[0m\n\u001b[0;32m   4090\u001b[0m     \u001b[1;31m# the value is discarded.\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   4091\u001b[0m     output_time_zero, _ = step_function(\n\u001b[1;32m-> 4092\u001b[1;33m         input_time_zero, tuple(initial_states) + tuple(constants))\n\u001b[0m\u001b[0;32m   4093\u001b[0m     output_ta = tuple(\n\u001b[0;32m   4094\u001b[0m         tensor_array_ops.TensorArray(\n",
      "\u001b[1;32m~\\AppData\\Local\\Programs\\Python\\Python37\\lib\\site-packages\\tensorflow\\python\\keras\\layers\\recurrent_v2.py\u001b[0m in \u001b[0;36mstep\u001b[1;34m(inputs, states)\u001b[0m\n\u001b[0;32m   1124\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1125\u001b[0m       \u001b[1;32mdef\u001b[0m \u001b[0mstep\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0minputs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mstates\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1126\u001b[1;33m         \u001b[1;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mcell\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0minputs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mstates\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   1127\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1128\u001b[0m       last_output, outputs, states = K.rnn(\n",
      "\u001b[1;32m~\\AppData\\Local\\Programs\\Python\\Python37\\lib\\site-packages\\tensorflow\\python\\keras\\engine\\base_layer.py\u001b[0m in \u001b[0;36m__call__\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m    920\u001b[0m                     not base_layer_utils.is_in_eager_or_tf_function()):\n\u001b[0;32m    921\u001b[0m                   \u001b[1;32mwith\u001b[0m \u001b[0mauto_control_deps\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mAutomaticControlDependencies\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;32mas\u001b[0m \u001b[0macd\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 922\u001b[1;33m                     \u001b[0moutputs\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mcall_fn\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mcast_inputs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m*\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    923\u001b[0m                     \u001b[1;31m# Wrap Tensors in `outputs` in `tf.identity` to avoid\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    924\u001b[0m                     \u001b[1;31m# circular dependencies.\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\AppData\\Local\\Programs\\Python\\Python37\\lib\\site-packages\\tensorflow\\python\\keras\\layers\\recurrent.py\u001b[0m in \u001b[0;36mcall\u001b[1;34m(self, inputs, states, training)\u001b[0m\n\u001b[0;32m   2428\u001b[0m       \u001b[0mz\u001b[0m \u001b[1;33m+=\u001b[0m \u001b[0mK\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mdot\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mh_tm1\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mrecurrent_kernel\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   2429\u001b[0m       \u001b[1;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0muse_bias\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 2430\u001b[1;33m         \u001b[0mz\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mK\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mbias_add\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mz\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mbias\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   2431\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   2432\u001b[0m       \u001b[0mz\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0marray_ops\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0msplit\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mz\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mnum_or_size_splits\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m4\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0maxis\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\AppData\\Local\\Programs\\Python\\Python37\\lib\\site-packages\\tensorflow\\python\\keras\\backend.py\u001b[0m in \u001b[0;36mbias_add\u001b[1;34m(x, bias, data_format)\u001b[0m\n\u001b[0;32m   5622\u001b[0m   \u001b[1;32mif\u001b[0m \u001b[0mlen\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mbias_shape\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;33m==\u001b[0m \u001b[1;36m1\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   5623\u001b[0m     \u001b[1;32mif\u001b[0m \u001b[0mdata_format\u001b[0m \u001b[1;33m==\u001b[0m \u001b[1;34m'channels_first'\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 5624\u001b[1;33m       \u001b[1;32mreturn\u001b[0m \u001b[0mnn\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mbias_add\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mx\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mbias\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mdata_format\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;34m'NCHW'\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   5625\u001b[0m     \u001b[1;32mreturn\u001b[0m \u001b[0mnn\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mbias_add\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mx\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mbias\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mdata_format\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;34m'NHWC'\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   5626\u001b[0m   \u001b[1;32mif\u001b[0m \u001b[0mndim\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mx\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;32min\u001b[0m \u001b[1;33m(\u001b[0m\u001b[1;36m3\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;36m4\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;36m5\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\AppData\\Local\\Programs\\Python\\Python37\\lib\\site-packages\\tensorflow\\python\\ops\\nn_ops.py\u001b[0m in \u001b[0;36mbias_add\u001b[1;34m(value, bias, data_format, name)\u001b[0m\n\u001b[0;32m   2795\u001b[0m     \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   2796\u001b[0m       return gen_nn_ops.bias_add(\n\u001b[1;32m-> 2797\u001b[1;33m           value, bias, data_format=data_format, name=name)\n\u001b[0m\u001b[0;32m   2798\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   2799\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\AppData\\Local\\Programs\\Python\\Python37\\lib\\site-packages\\tensorflow\\python\\ops\\gen_nn_ops.py\u001b[0m in \u001b[0;36mbias_add\u001b[1;34m(value, bias, data_format, name)\u001b[0m\n\u001b[0;32m    685\u001b[0m   \u001b[0mdata_format\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0m_execute\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mmake_str\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mdata_format\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;34m\"data_format\"\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    686\u001b[0m   _, _, _op, _outputs = _op_def_library._apply_op_helper(\n\u001b[1;32m--> 687\u001b[1;33m         \"BiasAdd\", value=value, bias=bias, data_format=data_format, name=name)\n\u001b[0m\u001b[0;32m    688\u001b[0m   \u001b[0m_result\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0m_outputs\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    689\u001b[0m   \u001b[1;32mif\u001b[0m \u001b[0m_execute\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mmust_record_gradient\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\AppData\\Local\\Programs\\Python\\Python37\\lib\\site-packages\\tensorflow\\python\\framework\\op_def_library.py\u001b[0m in \u001b[0;36m_apply_op_helper\u001b[1;34m(op_type_name, name, **keywords)\u001b[0m\n\u001b[0;32m    742\u001b[0m       op = g._create_op_internal(op_type_name, inputs, dtypes=None,\n\u001b[0;32m    743\u001b[0m                                  \u001b[0mname\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mscope\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0minput_types\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0minput_types\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 744\u001b[1;33m                                  attrs=attr_protos, op_def=op_def)\n\u001b[0m\u001b[0;32m    745\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    746\u001b[0m     \u001b[1;31m# `outputs` is returned as a separate return value so that the output\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\AppData\\Local\\Programs\\Python\\Python37\\lib\\site-packages\\tensorflow\\python\\framework\\func_graph.py\u001b[0m in \u001b[0;36m_create_op_internal\u001b[1;34m(self, op_type, inputs, dtypes, input_types, name, attrs, op_def, compute_device)\u001b[0m\n\u001b[0;32m    593\u001b[0m     return super(FuncGraph, self)._create_op_internal(  # pylint: disable=protected-access\n\u001b[0;32m    594\u001b[0m         \u001b[0mop_type\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0minputs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mdtypes\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0minput_types\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mname\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mattrs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mop_def\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 595\u001b[1;33m         compute_device)\n\u001b[0m\u001b[0;32m    596\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    597\u001b[0m   \u001b[1;32mdef\u001b[0m \u001b[0mcapture\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mtensor\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mname\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;32mNone\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mshape\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;32mNone\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\AppData\\Local\\Programs\\Python\\Python37\\lib\\site-packages\\tensorflow\\python\\framework\\ops.py\u001b[0m in \u001b[0;36m_create_op_internal\u001b[1;34m(self, op_type, inputs, dtypes, input_types, name, attrs, op_def, compute_device)\u001b[0m\n\u001b[0;32m   3325\u001b[0m           \u001b[0minput_types\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0minput_types\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   3326\u001b[0m           \u001b[0moriginal_op\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_default_original_op\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 3327\u001b[1;33m           op_def=op_def)\n\u001b[0m\u001b[0;32m   3328\u001b[0m       \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_create_op_helper\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mret\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mcompute_device\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mcompute_device\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   3329\u001b[0m     \u001b[1;32mreturn\u001b[0m \u001b[0mret\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\AppData\\Local\\Programs\\Python\\Python37\\lib\\site-packages\\tensorflow\\python\\framework\\ops.py\u001b[0m in \u001b[0;36m__init__\u001b[1;34m(self, node_def, g, inputs, output_types, control_inputs, input_types, original_op, op_def)\u001b[0m\n\u001b[0;32m   1815\u001b[0m         \u001b[0mop_def\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_graph\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_get_op_def\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mnode_def\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mop\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1816\u001b[0m       self._c_op = _create_c_op(self._graph, node_def, inputs,\n\u001b[1;32m-> 1817\u001b[1;33m                                 control_input_ops, op_def)\n\u001b[0m\u001b[0;32m   1818\u001b[0m       \u001b[0mname\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mcompat\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mas_str\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mnode_def\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mname\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1819\u001b[0m     \u001b[1;31m# pylint: enable=protected-access\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\AppData\\Local\\Programs\\Python\\Python37\\lib\\site-packages\\tensorflow\\python\\framework\\ops.py\u001b[0m in \u001b[0;36m_create_c_op\u001b[1;34m(graph, node_def, inputs, control_inputs, op_def)\u001b[0m\n\u001b[0;32m   1655\u001b[0m   \u001b[1;32mexcept\u001b[0m \u001b[0merrors\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mInvalidArgumentError\u001b[0m \u001b[1;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1656\u001b[0m     \u001b[1;31m# Convert to ValueError for backwards compatibility.\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1657\u001b[1;33m     \u001b[1;32mraise\u001b[0m \u001b[0mValueError\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mstr\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0me\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   1658\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1659\u001b[0m   \u001b[1;32mreturn\u001b[0m \u001b[0mc_op\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mValueError\u001b[0m: Shape must be at least rank 3 but is rank 2 for '{{node lstm_2/lstm_cell_2/BiasAdd}} = BiasAdd[T=DT_FLOAT, data_format=\"NCHW\"](lstm_2/lstm_cell_2/add, lstm_2/lstm_cell_2/BiasAdd/ReadVariableOp)' with input shapes: [?,160], [160]."
     ]
    }
   ],
   "source": [
    "# model = Sequential()\n",
    "# model.add(Conv2D(40, (30, 1), activation=\"relu\", kernel_regularizer=regularizers.l1(0), padding=\"same\", input_shape=(200, 60, 1), data_format=\"channels_last\"))\n",
    "# model.add(Conv2D(40, (1, 60), activation=\"relu\", kernel_regularizer=regularizers.l1(0), padding=\"same\", data_format=\"channels_last\"))\n",
    "# model.add(AveragePooling2D((5, 1), strides=(5, 1)))\n",
    "# model.add(TimeDistributed(Flatten()))\n",
    "# model.add(LSTM(40, activation=\"sigmoid\", dropout=0.25, return_sequences=True))\n",
    "# model.add(Dense(nclasses, activation=\"softmax\"))\n",
    "# model.compile(loss=\"categorical_crossentropy\", optimizer=\"rmsprop\", metrics=[\"acc\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'model' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-8-f95163e7667c>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      3\u001b[0m \u001b[0mtrain_batch\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mBatchSequence\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mx_train\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0my_train\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mbatch_size\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      4\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 5\u001b[1;33m \u001b[0mmodel_fit\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mmodel\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mtrain_batch\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mepochs\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m8\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mcallbacks\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mearlystop_callback\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mvalidation_data\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mx_test\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0my_test\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m: name 'model' is not defined"
     ]
    }
   ],
   "source": [
    "# Train Model\n",
    "batch_size = 30\n",
    "train_batch = BatchSequence(x_train, y_train, batch_size)\n",
    "\n",
    "model_fit = model.fit(train_batch, epochs=8, callbacks=[earlystop_callback], validation_data=(x_test, y_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "model.save(os.path.join(os.getcwd(), \"train_with_clean_data.h5\"))\n",
    "print(f\"Saved model to disk\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "208/225 [==========================>...] - ETA: 0s - loss: 0.2225 - acc: 0.937 - ETA: 1:00 - loss: 0.3313 - acc: 0.890 - ETA: 1:20 - loss: 0.2698 - acc: 0.906 - ETA: 1:29 - loss: 0.2597 - acc: 0.898 - ETA: 1:37 - loss: 0.2512 - acc: 0.893 - ETA: 1:46 - loss: 0.2302 - acc: 0.901 - ETA: 1:52 - loss: 0.2282 - acc: 0.897 - ETA: 1:55 - loss: 0.2155 - acc: 0.902 - ETA: 1:56 - loss: 0.2235 - acc: 0.899 - ETA: 1:59 - loss: 0.2208 - acc: 0.903 - ETA: 2:01 - loss: 0.2166 - acc: 0.906 - ETA: 2:02 - loss: 0.2163 - acc: 0.903 - ETA: 2:02 - loss: 0.2141 - acc: 0.903 - ETA: 2:02 - loss: 0.2267 - acc: 0.899 - ETA: 2:03 - loss: 0.2282 - acc: 0.900 - ETA: 2:03 - loss: 0.2187 - acc: 0.904 - ETA: 2:03 - loss: 0.2304 - acc: 0.900 - ETA: 2:03 - loss: 0.2362 - acc: 0.894 - ETA: 2:04 - loss: 0.2308 - acc: 0.896 - ETA: 2:03 - loss: 0.2269 - acc: 0.896 - ETA: 2:03 - loss: 0.2235 - acc: 0.900 - ETA: 2:03 - loss: 0.2160 - acc: 0.903 - ETA: 2:03 - loss: 0.2145 - acc: 0.904 - ETA: 2:02 - loss: 0.2083 - acc: 0.907 - ETA: 2:03 - loss: 0.2061 - acc: 0.908 - ETA: 2:02 - loss: 0.2078 - acc: 0.907 - ETA: 2:02 - loss: 0.2038 - acc: 0.909 - ETA: 2:02 - loss: 0.2023 - acc: 0.909 - ETA: 2:01 - loss: 0.1996 - acc: 0.909 - ETA: 2:00 - loss: 0.1970 - acc: 0.911 - ETA: 2:00 - loss: 0.1955 - acc: 0.911 - ETA: 2:00 - loss: 0.1981 - acc: 0.912 - ETA: 2:00 - loss: 0.1972 - acc: 0.911 - ETA: 1:59 - loss: 0.1978 - acc: 0.910 - ETA: 1:59 - loss: 0.1988 - acc: 0.908 - ETA: 1:58 - loss: 0.1969 - acc: 0.909 - ETA: 1:58 - loss: 0.1995 - acc: 0.907 - ETA: 1:57 - loss: 0.2017 - acc: 0.905 - ETA: 1:57 - loss: 0.2033 - acc: 0.903 - ETA: 1:56 - loss: 0.2038 - acc: 0.902 - ETA: 1:56 - loss: 0.2040 - acc: 0.900 - ETA: 1:55 - loss: 0.2037 - acc: 0.900 - ETA: 1:55 - loss: 0.2020 - acc: 0.900 - ETA: 1:54 - loss: 0.2003 - acc: 0.901 - ETA: 1:53 - loss: 0.2013 - acc: 0.900 - ETA: 1:53 - loss: 0.1986 - acc: 0.901 - ETA: 1:52 - loss: 0.1997 - acc: 0.901 - ETA: 1:52 - loss: 0.2004 - acc: 0.901 - ETA: 1:51 - loss: 0.2029 - acc: 0.901 - ETA: 1:51 - loss: 0.2048 - acc: 0.901 - ETA: 1:50 - loss: 0.2064 - acc: 0.900 - ETA: 1:49 - loss: 0.2054 - acc: 0.900 - ETA: 1:49 - loss: 0.2029 - acc: 0.901 - ETA: 1:48 - loss: 0.2066 - acc: 0.900 - ETA: 1:48 - loss: 0.2082 - acc: 0.899 - ETA: 1:47 - loss: 0.2085 - acc: 0.899 - ETA: 1:47 - loss: 0.2073 - acc: 0.900 - ETA: 1:46 - loss: 0.2048 - acc: 0.901 - ETA: 1:45 - loss: 0.2047 - acc: 0.901 - ETA: 1:45 - loss: 0.2047 - acc: 0.901 - ETA: 1:44 - loss: 0.2047 - acc: 0.901 - ETA: 1:44 - loss: 0.2023 - acc: 0.902 - ETA: 1:43 - loss: 0.2022 - acc: 0.903 - ETA: 1:43 - loss: 0.2026 - acc: 0.902 - ETA: 1:43 - loss: 0.2087 - acc: 0.900 - ETA: 1:43 - loss: 0.2077 - acc: 0.900 - ETA: 1:42 - loss: 0.2096 - acc: 0.898 - ETA: 1:41 - loss: 0.2086 - acc: 0.898 - ETA: 1:41 - loss: 0.2090 - acc: 0.898 - ETA: 1:40 - loss: 0.2085 - acc: 0.898 - ETA: 1:40 - loss: 0.2079 - acc: 0.898 - ETA: 1:39 - loss: 0.2089 - acc: 0.898 - ETA: 1:38 - loss: 0.2099 - acc: 0.897 - ETA: 1:38 - loss: 0.2084 - acc: 0.898 - ETA: 1:37 - loss: 0.2106 - acc: 0.897 - ETA: 1:36 - loss: 0.2107 - acc: 0.898 - ETA: 1:35 - loss: 0.2131 - acc: 0.896 - ETA: 1:35 - loss: 0.2140 - acc: 0.895 - ETA: 1:34 - loss: 0.2134 - acc: 0.896 - ETA: 1:33 - loss: 0.2109 - acc: 0.897 - ETA: 1:33 - loss: 0.2127 - acc: 0.896 - ETA: 1:32 - loss: 0.2144 - acc: 0.895 - ETA: 1:31 - loss: 0.2150 - acc: 0.894 - ETA: 1:30 - loss: 0.2151 - acc: 0.895 - ETA: 1:30 - loss: 0.2169 - acc: 0.894 - ETA: 1:29 - loss: 0.2158 - acc: 0.895 - ETA: 1:28 - loss: 0.2157 - acc: 0.894 - ETA: 1:27 - loss: 0.2149 - acc: 0.894 - ETA: 1:27 - loss: 0.2162 - acc: 0.894 - ETA: 1:26 - loss: 0.2150 - acc: 0.894 - ETA: 1:25 - loss: 0.2156 - acc: 0.893 - ETA: 1:24 - loss: 0.2146 - acc: 0.894 - ETA: 1:24 - loss: 0.2156 - acc: 0.893 - ETA: 1:23 - loss: 0.2141 - acc: 0.894 - ETA: 1:22 - loss: 0.2174 - acc: 0.893 - ETA: 1:21 - loss: 0.2167 - acc: 0.894 - ETA: 1:21 - loss: 0.2160 - acc: 0.894 - ETA: 1:20 - loss: 0.2162 - acc: 0.894 - ETA: 1:19 - loss: 0.2155 - acc: 0.894 - ETA: 1:19 - loss: 0.2135 - acc: 0.895 - ETA: 1:18 - loss: 0.2127 - acc: 0.896 - ETA: 1:17 - loss: 0.2130 - acc: 0.896 - ETA: 1:16 - loss: 0.2131 - acc: 0.896 - ETA: 1:16 - loss: 0.2138 - acc: 0.896 - ETA: 1:15 - loss: 0.2133 - acc: 0.896 - ETA: 1:14 - loss: 0.2133 - acc: 0.896 - ETA: 1:14 - loss: 0.2139 - acc: 0.896 - ETA: 1:13 - loss: 0.2137 - acc: 0.896 - ETA: 1:12 - loss: 0.2121 - acc: 0.897 - ETA: 1:12 - loss: 0.2110 - acc: 0.897 - ETA: 1:11 - loss: 0.2110 - acc: 0.897 - ETA: 1:10 - loss: 0.2137 - acc: 0.896 - ETA: 1:09 - loss: 0.2134 - acc: 0.896 - ETA: 1:09 - loss: 0.2142 - acc: 0.896 - ETA: 1:08 - loss: 0.2140 - acc: 0.895 - ETA: 1:07 - loss: 0.2145 - acc: 0.895 - ETA: 1:07 - loss: 0.2141 - acc: 0.896 - ETA: 1:06 - loss: 0.2149 - acc: 0.895 - ETA: 1:05 - loss: 0.2180 - acc: 0.895 - ETA: 1:05 - loss: 0.2169 - acc: 0.896 - ETA: 1:04 - loss: 0.2185 - acc: 0.895 - ETA: 1:03 - loss: 0.2178 - acc: 0.896 - ETA: 1:03 - loss: 0.2186 - acc: 0.895 - ETA: 1:02 - loss: 0.2179 - acc: 0.896 - ETA: 1:01 - loss: 0.2181 - acc: 0.896 - ETA: 1:01 - loss: 0.2187 - acc: 0.895 - ETA: 1:00 - loss: 0.2190 - acc: 0.895 - ETA: 59s - loss: 0.2186 - acc: 0.895 - ETA: 59s - loss: 0.2181 - acc: 0.89 - ETA: 58s - loss: 0.2184 - acc: 0.89 - ETA: 58s - loss: 0.2212 - acc: 0.89 - ETA: 57s - loss: 0.2218 - acc: 0.89 - ETA: 56s - loss: 0.2216 - acc: 0.89 - ETA: 56s - loss: 0.2208 - acc: 0.89 - ETA: 55s - loss: 0.2210 - acc: 0.89 - ETA: 54s - loss: 0.2218 - acc: 0.89 - ETA: 54s - loss: 0.2220 - acc: 0.89 - ETA: 53s - loss: 0.2215 - acc: 0.89 - ETA: 52s - loss: 0.2229 - acc: 0.89 - ETA: 52s - loss: 0.2224 - acc: 0.89 - ETA: 51s - loss: 0.2222 - acc: 0.89 - ETA: 50s - loss: 0.2227 - acc: 0.89 - ETA: 50s - loss: 0.2231 - acc: 0.89 - ETA: 49s - loss: 0.2230 - acc: 0.89 - ETA: 49s - loss: 0.2235 - acc: 0.89 - ETA: 48s - loss: 0.2231 - acc: 0.89 - ETA: 47s - loss: 0.2226 - acc: 0.89 - ETA: 47s - loss: 0.2220 - acc: 0.89 - ETA: 46s - loss: 0.2212 - acc: 0.89 - ETA: 45s - loss: 0.2206 - acc: 0.89 - ETA: 45s - loss: 0.2243 - acc: 0.89 - ETA: 44s - loss: 0.2248 - acc: 0.89 - ETA: 43s - loss: 0.2246 - acc: 0.89 - ETA: 43s - loss: 0.2239 - acc: 0.89 - ETA: 42s - loss: 0.2245 - acc: 0.89 - ETA: 42s - loss: 0.2238 - acc: 0.89 - ETA: 41s - loss: 0.2248 - acc: 0.89 - ETA: 40s - loss: 0.2248 - acc: 0.89 - ETA: 40s - loss: 0.2242 - acc: 0.89 - ETA: 39s - loss: 0.2241 - acc: 0.89 - ETA: 38s - loss: 0.2250 - acc: 0.89 - ETA: 38s - loss: 0.2247 - acc: 0.89 - ETA: 37s - loss: 0.2242 - acc: 0.89 - ETA: 37s - loss: 0.2238 - acc: 0.89 - ETA: 36s - loss: 0.2229 - acc: 0.89 - ETA: 35s - loss: 0.2231 - acc: 0.89 - ETA: 35s - loss: 0.2227 - acc: 0.89 - ETA: 34s - loss: 0.2227 - acc: 0.89 - ETA: 34s - loss: 0.2222 - acc: 0.89 - ETA: 33s - loss: 0.2226 - acc: 0.89 - ETA: 32s - loss: 0.2242 - acc: 0.89 - ETA: 32s - loss: 0.2240 - acc: 0.89 - ETA: 31s - loss: 0.2236 - acc: 0.89 - ETA: 31s - loss: 0.2241 - acc: 0.89 - ETA: 30s - loss: 0.2240 - acc: 0.89 - ETA: 29s - loss: 0.2239 - acc: 0.89 - ETA: 29s - loss: 0.2237 - acc: 0.89 - ETA: 28s - loss: 0.2236 - acc: 0.89 - ETA: 27s - loss: 0.2238 - acc: 0.89 - ETA: 27s - loss: 0.2229 - acc: 0.89 - ETA: 26s - loss: 0.2232 - acc: 0.89 - ETA: 26s - loss: 0.2230 - acc: 0.89 - ETA: 25s - loss: 0.2230 - acc: 0.89 - ETA: 24s - loss: 0.2237 - acc: 0.89 - ETA: 24s - loss: 0.2230 - acc: 0.89 - ETA: 23s - loss: 0.2230 - acc: 0.89 - ETA: 22s - loss: 0.2223 - acc: 0.89 - ETA: 22s - loss: 0.2216 - acc: 0.89 - ETA: 21s - loss: 0.2217 - acc: 0.89 - ETA: 21s - loss: 0.2211 - acc: 0.89 - ETA: 20s - loss: 0.2217 - acc: 0.89 - ETA: 19s - loss: 0.2211 - acc: 0.89 - ETA: 19s - loss: 0.2212 - acc: 0.89 - ETA: 18s - loss: 0.2211 - acc: 0.89 - ETA: 18s - loss: 0.2219 - acc: 0.89 - ETA: 17s - loss: 0.2221 - acc: 0.89 - ETA: 16s - loss: 0.2219 - acc: 0.89 - ETA: 16s - loss: 0.2216 - acc: 0.89 - ETA: 15s - loss: 0.2226 - acc: 0.89 - ETA: 15s - loss: 0.2233 - acc: 0.89 - ETA: 14s - loss: 0.2237 - acc: 0.89 - ETA: 13s - loss: 0.2241 - acc: 0.89 - ETA: 13s - loss: 0.2239 - acc: 0.89 - ETA: 12s - loss: 0.2249 - acc: 0.89 - ETA: 12s - loss: 0.2248 - acc: 0.89 - ETA: 11s - loss: 0.2246 - acc: 0.89 - ETA: 10s - loss: 0.2252 - acc: 0.89 - ETA: 10s - loss: 0.2249 - acc: 0.8953"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "225/225 [==============================] - ETA: 9s - loss: 0.2246 - acc: 0.8953 - ETA: 9s - loss: 0.2248 - acc: 0.895 - ETA: 8s - loss: 0.2241 - acc: 0.895 - ETA: 7s - loss: 0.2241 - acc: 0.895 - ETA: 7s - loss: 0.2237 - acc: 0.895 - ETA: 6s - loss: 0.2231 - acc: 0.896 - ETA: 6s - loss: 0.2238 - acc: 0.895 - ETA: 5s - loss: 0.2233 - acc: 0.895 - ETA: 4s - loss: 0.2231 - acc: 0.895 - ETA: 4s - loss: 0.2230 - acc: 0.896 - ETA: 3s - loss: 0.2223 - acc: 0.896 - ETA: 3s - loss: 0.2223 - acc: 0.896 - ETA: 2s - loss: 0.2219 - acc: 0.896 - ETA: 1s - loss: 0.2213 - acc: 0.896 - ETA: 1s - loss: 0.2208 - acc: 0.897 - ETA: 0s - loss: 0.2208 - acc: 0.897 - ETA: 0s - loss: 0.2211 - acc: 0.896 - 135s 599ms/step - loss: 0.2211 - acc: 0.8968\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[0.22108995914459229, 0.8968441486358643]"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from tensorflow.python.keras.models import load_model\n",
    "\n",
    "# Predict Model\n",
    "# clean_model = load_model(\"train_with_clean_data.h5\")\n",
    "\n",
    "# model = load_model(\"model.h5\")\n",
    "\n",
    "model2 = load_model(\"model2.h5\")\n",
    "\n",
    "model2.evaluate(x_train, y_train)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.7.4 64-bit",
   "language": "python",
   "name": "python37464bit7e485a10f5514aadadc957c9e69ac534"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
